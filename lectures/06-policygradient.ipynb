{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\евгений\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "c:\\users\\евгений\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def store(self, exptuple):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = exptuple\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "       \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, layer_size=256):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, layer_size)\n",
    "        self.l2 = nn.Linear(layer_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations(xs, labels):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.xlabel('Номер эпизода')\n",
    "    plt.ylabel('Число шагов')\n",
    "    for i,x in enumerate(xs):\n",
    "        plt.plot(x, label=labels[i])\n",
    "    plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartpoleDQN():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        self.model = Network()\n",
    "        self.memory = ReplayMemory(10000)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), 0.001)\n",
    "        self.steps_done = 0\n",
    "        self.episode_durations = []\n",
    "        \n",
    "        self.gamma = 0.8\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.eps_init, self.eps_final, self.eps_decay = 0.9, 0.05, 200\n",
    "        self.num_step = 0\n",
    "\n",
    "    def select_greedy_action(self, state):\n",
    "        return self.model(state).data.max(1)[1].view(1, 1)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        self.num_step += 1\n",
    "        eps_threshold = self.eps_final + (self.eps_init - self.eps_final) * math.exp(-1. * self.num_step / self.eps_decay)\n",
    "        if sample > eps_threshold:\n",
    "            return self.select_greedy_action(state)\n",
    "        else:\n",
    "            return torch.tensor([[random.randrange(2)]], dtype=torch.int64)\n",
    "        \n",
    "    def run_episode(self, e=0, do_learning=True, greedy=False, render=False):\n",
    "        state, num_step = self.env.reset(), 0\n",
    "        while True:\n",
    "            if render:\n",
    "                self.env.render()\n",
    "\n",
    "            state_tensor = torch.tensor([state], dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                if greedy:\n",
    "                    action = self.select_greedy_action(state_tensor)\n",
    "                else:\n",
    "                    action = self.select_action(state_tensor)\n",
    "            next_state, reward, done, _ = self.env.step(action.numpy()[0][0])\n",
    "            next_state_tensor = torch.tensor([next_state], dtype=torch.float32)\n",
    "\n",
    "            if done:\n",
    "                reward = -1\n",
    "\n",
    "            transition = (state_tensor, action, next_state_tensor, torch.tensor([reward], dtype=torch.float32))\n",
    "            self.memory.store(transition)\n",
    "\n",
    "            if do_learning:\n",
    "                self.learn()\n",
    "\n",
    "            state = next_state\n",
    "            num_step += 1\n",
    "\n",
    "            if done:\n",
    "                print(\"\\tepisode %d finished after %d steps\" % (e, num_step))\n",
    "                self.episode_durations.append(num_step)\n",
    "                break\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        # берём мини-батч из памяти\n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        batch_state, batch_action, batch_next_state, batch_reward = zip(*transitions)\n",
    "\n",
    "        batch_state = Variable(torch.cat(batch_state))\n",
    "        batch_action = Variable(torch.cat(batch_action))\n",
    "        batch_reward = Variable(torch.cat(batch_reward))\n",
    "        batch_next_state = Variable(torch.cat(batch_next_state))\n",
    "\n",
    "        # считаем значения функции Q\n",
    "        Q = self.model(batch_state).gather(1, batch_action).reshape([self.batch_size])\n",
    "\n",
    "        # оцениваем ожидаемые значения после этого действия\n",
    "        Qmax = self.model(batch_next_state).detach().max(1)[0]\n",
    "        Qnext = batch_reward + (self.gamma * Qmax)\n",
    "\n",
    "        # и хотим, чтобы Q было похоже на Qnext -- это и есть суть Q-обучения\n",
    "        loss = F.smooth_l1_loss(Q, Qnext)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:11:38.110155\tStarting training for 300 episodes...\n",
      "\tepisode 0 finished after 30 steps\n",
      "\tepisode 1 finished after 22 steps\n",
      "\tepisode 2 finished after 13 steps\n",
      "\tepisode 3 finished after 12 steps\n",
      "\tepisode 4 finished after 19 steps\n",
      "\tepisode 5 finished after 20 steps\n",
      "\tepisode 6 finished after 12 steps\n",
      "\tepisode 7 finished after 11 steps\n",
      "\tepisode 8 finished after 16 steps\n",
      "\tepisode 9 finished after 12 steps\n",
      "\tepisode 10 finished after 11 steps\n",
      "\tepisode 11 finished after 15 steps\n",
      "\tepisode 12 finished after 9 steps\n",
      "\tepisode 13 finished after 10 steps\n",
      "\tepisode 14 finished after 10 steps\n",
      "\tepisode 15 finished after 14 steps\n",
      "\tepisode 16 finished after 11 steps\n",
      "\tepisode 17 finished after 14 steps\n",
      "\tepisode 18 finished after 8 steps\n",
      "\tepisode 19 finished after 11 steps\n",
      "\tepisode 20 finished after 11 steps\n",
      "\tepisode 21 finished after 13 steps\n",
      "\tepisode 22 finished after 13 steps\n",
      "\tepisode 23 finished after 10 steps\n",
      "\tepisode 24 finished after 9 steps\n",
      "\tepisode 25 finished after 14 steps\n",
      "\tepisode 26 finished after 12 steps\n",
      "\tepisode 27 finished after 17 steps\n",
      "\tepisode 28 finished after 15 steps\n",
      "\tepisode 29 finished after 42 steps\n",
      "\tepisode 30 finished after 23 steps\n",
      "\tepisode 31 finished after 18 steps\n",
      "\tepisode 32 finished after 25 steps\n",
      "\tepisode 33 finished after 25 steps\n",
      "\tepisode 34 finished after 21 steps\n",
      "\tepisode 35 finished after 28 steps\n",
      "\tepisode 36 finished after 25 steps\n",
      "\tepisode 37 finished after 24 steps\n",
      "\tepisode 38 finished after 37 steps\n",
      "\tepisode 39 finished after 30 steps\n",
      "\tepisode 40 finished after 28 steps\n",
      "\tepisode 41 finished after 35 steps\n",
      "\tepisode 42 finished after 45 steps\n",
      "\tepisode 43 finished after 79 steps\n",
      "\tepisode 44 finished after 109 steps\n",
      "\tepisode 45 finished after 118 steps\n",
      "\tepisode 46 finished after 200 steps\n",
      "\tepisode 47 finished after 200 steps\n",
      "\tepisode 48 finished after 200 steps\n",
      "\tepisode 49 finished after 153 steps\n",
      "\tepisode 50 finished after 162 steps\n",
      "\tepisode 51 finished after 130 steps\n",
      "\tepisode 52 finished after 165 steps\n",
      "\tepisode 53 finished after 186 steps\n",
      "\tepisode 54 finished after 200 steps\n",
      "\tepisode 55 finished after 163 steps\n",
      "\tepisode 56 finished after 200 steps\n",
      "\tepisode 57 finished after 200 steps\n",
      "\tepisode 58 finished after 200 steps\n",
      "\tepisode 59 finished after 182 steps\n",
      "\tepisode 60 finished after 160 steps\n",
      "\tepisode 61 finished after 165 steps\n",
      "\tepisode 62 finished after 173 steps\n",
      "\tepisode 63 finished after 177 steps\n",
      "\tepisode 64 finished after 168 steps\n",
      "\tepisode 65 finished after 189 steps\n",
      "\tepisode 66 finished after 200 steps\n",
      "\tepisode 67 finished after 191 steps\n",
      "\tepisode 68 finished after 200 steps\n",
      "\tepisode 69 finished after 153 steps\n",
      "\tepisode 70 finished after 200 steps\n",
      "\tepisode 71 finished after 200 steps\n",
      "\tepisode 72 finished after 179 steps\n",
      "\tepisode 73 finished after 200 steps\n",
      "\tepisode 74 finished after 200 steps\n",
      "\tepisode 75 finished after 163 steps\n",
      "\tepisode 76 finished after 197 steps\n",
      "\tepisode 77 finished after 190 steps\n",
      "\tepisode 78 finished after 200 steps\n",
      "\tepisode 79 finished after 192 steps\n",
      "\tepisode 80 finished after 178 steps\n",
      "\tepisode 81 finished after 169 steps\n",
      "\tepisode 82 finished after 200 steps\n",
      "\tepisode 83 finished after 166 steps\n",
      "\tepisode 84 finished after 184 steps\n",
      "\tepisode 85 finished after 184 steps\n",
      "\tepisode 86 finished after 166 steps\n",
      "\tepisode 87 finished after 200 steps\n",
      "\tepisode 88 finished after 183 steps\n",
      "\tepisode 89 finished after 160 steps\n",
      "\tepisode 90 finished after 145 steps\n",
      "\tepisode 91 finished after 168 steps\n",
      "\tepisode 92 finished after 200 steps\n",
      "\tepisode 93 finished after 200 steps\n",
      "\tepisode 94 finished after 200 steps\n",
      "\tepisode 95 finished after 170 steps\n",
      "\tepisode 96 finished after 171 steps\n",
      "\tepisode 97 finished after 148 steps\n",
      "\tepisode 98 finished after 148 steps\n",
      "\tepisode 99 finished after 200 steps\n",
      "\tepisode 100 finished after 166 steps\n",
      "\tepisode 101 finished after 200 steps\n",
      "\tepisode 102 finished after 200 steps\n",
      "\tepisode 103 finished after 200 steps\n",
      "\tepisode 104 finished after 200 steps\n",
      "\tepisode 105 finished after 200 steps\n",
      "\tepisode 106 finished after 184 steps\n",
      "\tepisode 107 finished after 200 steps\n",
      "\tepisode 108 finished after 198 steps\n",
      "\tepisode 109 finished after 179 steps\n",
      "\tepisode 110 finished after 200 steps\n",
      "\tepisode 111 finished after 162 steps\n",
      "\tepisode 112 finished after 143 steps\n",
      "\tepisode 113 finished after 200 steps\n",
      "\tepisode 114 finished after 182 steps\n",
      "\tepisode 115 finished after 126 steps\n",
      "\tepisode 116 finished after 142 steps\n",
      "\tepisode 117 finished after 172 steps\n",
      "\tepisode 118 finished after 154 steps\n",
      "\tepisode 119 finished after 158 steps\n",
      "\tepisode 120 finished after 42 steps\n",
      "\tepisode 121 finished after 170 steps\n",
      "\tepisode 122 finished after 54 steps\n",
      "\tepisode 123 finished after 13 steps\n",
      "\tepisode 124 finished after 181 steps\n",
      "\tepisode 125 finished after 189 steps\n",
      "\tepisode 126 finished after 200 steps\n",
      "\tepisode 127 finished after 151 steps\n",
      "\tepisode 128 finished after 200 steps\n",
      "\tepisode 129 finished after 155 steps\n",
      "\tepisode 130 finished after 144 steps\n",
      "\tepisode 131 finished after 146 steps\n",
      "\tepisode 132 finished after 187 steps\n",
      "\tepisode 133 finished after 200 steps\n",
      "\tepisode 134 finished after 200 steps\n",
      "\tepisode 135 finished after 156 steps\n",
      "\tepisode 136 finished after 200 steps\n",
      "\tepisode 137 finished after 190 steps\n",
      "\tepisode 138 finished after 163 steps\n",
      "\tepisode 139 finished after 163 steps\n",
      "\tepisode 140 finished after 189 steps\n",
      "\tepisode 141 finished after 32 steps\n",
      "\tepisode 142 finished after 200 steps\n",
      "\tepisode 143 finished after 152 steps\n",
      "\tepisode 144 finished after 158 steps\n",
      "\tepisode 145 finished after 124 steps\n",
      "\tepisode 146 finished after 199 steps\n",
      "\tepisode 147 finished after 64 steps\n",
      "\tepisode 148 finished after 194 steps\n",
      "\tepisode 149 finished after 200 steps\n",
      "\tepisode 150 finished after 197 steps\n",
      "\tepisode 151 finished after 177 steps\n",
      "\tepisode 152 finished after 164 steps\n",
      "\tepisode 153 finished after 175 steps\n",
      "\tepisode 154 finished after 200 steps\n",
      "\tepisode 155 finished after 192 steps\n",
      "\tepisode 156 finished after 13 steps\n",
      "\tepisode 157 finished after 200 steps\n",
      "\tepisode 158 finished after 154 steps\n",
      "\tepisode 159 finished after 162 steps\n",
      "\tepisode 160 finished after 174 steps\n",
      "\tepisode 161 finished after 200 steps\n",
      "\tepisode 162 finished after 191 steps\n",
      "\tepisode 163 finished after 200 steps\n",
      "\tepisode 164 finished after 200 steps\n",
      "\tepisode 165 finished after 200 steps\n",
      "\tepisode 166 finished after 151 steps\n",
      "\tepisode 167 finished after 187 steps\n",
      "\tepisode 168 finished after 32 steps\n",
      "\tepisode 169 finished after 150 steps\n",
      "\tepisode 170 finished after 175 steps\n",
      "\tepisode 171 finished after 159 steps\n",
      "\tepisode 172 finished after 183 steps\n",
      "\tepisode 173 finished after 136 steps\n",
      "\tepisode 174 finished after 200 steps\n",
      "\tepisode 175 finished after 182 steps\n",
      "\tepisode 176 finished after 53 steps\n",
      "\tepisode 177 finished after 185 steps\n",
      "\tepisode 178 finished after 200 steps\n",
      "\tepisode 179 finished after 135 steps\n",
      "\tepisode 180 finished after 200 steps\n",
      "\tepisode 181 finished after 200 steps\n",
      "\tepisode 182 finished after 71 steps\n",
      "\tepisode 183 finished after 130 steps\n",
      "\tepisode 184 finished after 196 steps\n",
      "\tepisode 185 finished after 200 steps\n",
      "\tepisode 186 finished after 181 steps\n",
      "\tepisode 187 finished after 137 steps\n",
      "\tepisode 188 finished after 200 steps\n",
      "\tepisode 189 finished after 111 steps\n",
      "\tepisode 190 finished after 200 steps\n",
      "\tepisode 191 finished after 167 steps\n",
      "\tepisode 192 finished after 184 steps\n",
      "\tepisode 193 finished after 200 steps\n",
      "\tepisode 194 finished after 194 steps\n",
      "\tepisode 195 finished after 200 steps\n",
      "\tepisode 196 finished after 19 steps\n",
      "\tepisode 197 finished after 200 steps\n",
      "\tepisode 198 finished after 191 steps\n",
      "\tepisode 199 finished after 164 steps\n",
      "\tepisode 200 finished after 200 steps\n",
      "\tepisode 201 finished after 172 steps\n",
      "\tepisode 202 finished after 162 steps\n",
      "\tepisode 203 finished after 200 steps\n",
      "\tepisode 204 finished after 200 steps\n",
      "\tepisode 205 finished after 200 steps\n",
      "\tepisode 206 finished after 37 steps\n",
      "\tepisode 207 finished after 166 steps\n",
      "\tepisode 208 finished after 200 steps\n",
      "\tepisode 209 finished after 200 steps\n",
      "\tepisode 210 finished after 186 steps\n",
      "\tepisode 211 finished after 190 steps\n",
      "\tepisode 212 finished after 200 steps\n",
      "\tepisode 213 finished after 177 steps\n",
      "\tepisode 214 finished after 27 steps\n",
      "\tepisode 215 finished after 200 steps\n",
      "\tepisode 216 finished after 132 steps\n",
      "\tepisode 217 finished after 106 steps\n",
      "\tepisode 218 finished after 200 steps\n",
      "\tepisode 219 finished after 200 steps\n",
      "\tepisode 220 finished after 174 steps\n",
      "\tepisode 221 finished after 160 steps\n",
      "\tepisode 222 finished after 193 steps\n",
      "\tepisode 223 finished after 200 steps\n",
      "\tepisode 224 finished after 158 steps\n",
      "\tepisode 225 finished after 200 steps\n",
      "\tepisode 226 finished after 200 steps\n",
      "\tepisode 227 finished after 68 steps\n",
      "\tepisode 228 finished after 90 steps\n",
      "\tepisode 229 finished after 200 steps\n",
      "\tepisode 230 finished after 175 steps\n",
      "\tepisode 231 finished after 187 steps\n",
      "\tepisode 232 finished after 40 steps\n",
      "\tepisode 233 finished after 60 steps\n",
      "\tepisode 234 finished after 200 steps\n",
      "\tepisode 235 finished after 200 steps\n",
      "\tepisode 236 finished after 80 steps\n",
      "\tepisode 237 finished after 200 steps\n",
      "\tepisode 238 finished after 200 steps\n",
      "\tepisode 239 finished after 200 steps\n",
      "\tepisode 240 finished after 46 steps\n",
      "\tepisode 241 finished after 140 steps\n",
      "\tepisode 242 finished after 186 steps\n",
      "\tepisode 243 finished after 200 steps\n",
      "\tepisode 244 finished after 200 steps\n",
      "\tepisode 245 finished after 200 steps\n",
      "\tepisode 246 finished after 158 steps\n",
      "\tepisode 247 finished after 142 steps\n",
      "\tepisode 248 finished after 200 steps\n",
      "\tepisode 249 finished after 190 steps\n",
      "\tepisode 250 finished after 200 steps\n",
      "\tepisode 251 finished after 172 steps\n",
      "\tepisode 252 finished after 171 steps\n",
      "\tepisode 253 finished after 200 steps\n",
      "\tepisode 254 finished after 46 steps\n",
      "\tepisode 255 finished after 152 steps\n",
      "\tepisode 256 finished after 200 steps\n",
      "\tepisode 257 finished after 200 steps\n",
      "\tepisode 258 finished after 200 steps\n",
      "\tepisode 259 finished after 190 steps\n",
      "\tepisode 260 finished after 63 steps\n",
      "\tepisode 261 finished after 200 steps\n",
      "\tepisode 262 finished after 200 steps\n",
      "\tepisode 263 finished after 200 steps\n",
      "\tepisode 264 finished after 200 steps\n",
      "\tepisode 265 finished after 200 steps\n",
      "\tepisode 266 finished after 69 steps\n",
      "\tepisode 267 finished after 148 steps\n",
      "\tepisode 268 finished after 200 steps\n",
      "\tepisode 269 finished after 200 steps\n",
      "\tepisode 270 finished after 200 steps\n",
      "\tepisode 271 finished after 170 steps\n",
      "\tepisode 272 finished after 142 steps\n",
      "\tepisode 273 finished after 186 steps\n",
      "\tepisode 274 finished after 182 steps\n",
      "\tepisode 275 finished after 139 steps\n",
      "\tepisode 276 finished after 162 steps\n",
      "\tepisode 277 finished after 140 steps\n",
      "\tepisode 278 finished after 200 steps\n",
      "\tepisode 279 finished after 171 steps\n",
      "\tepisode 280 finished after 199 steps\n",
      "\tepisode 281 finished after 200 steps\n",
      "\tepisode 282 finished after 193 steps\n",
      "\tepisode 283 finished after 200 steps\n",
      "\tepisode 284 finished after 174 steps\n",
      "\tepisode 285 finished after 190 steps\n",
      "\tepisode 286 finished after 164 steps\n",
      "\tepisode 287 finished after 134 steps\n",
      "\tepisode 288 finished after 131 steps\n",
      "\tepisode 289 finished after 122 steps\n",
      "\tepisode 290 finished after 150 steps\n",
      "\tepisode 291 finished after 200 steps\n",
      "\tepisode 292 finished after 162 steps\n",
      "\tepisode 293 finished after 150 steps\n",
      "\tepisode 294 finished after 159 steps\n",
      "\tepisode 295 finished after 200 steps\n",
      "\tepisode 296 finished after 126 steps\n",
      "\tepisode 297 finished after 29 steps\n",
      "\tepisode 298 finished after 200 steps\n",
      "\tepisode 299 finished after 184 steps\n",
      "19:13:04.210124\t\t...done!\n"
     ]
    }
   ],
   "source": [
    "dqn = CartpoleDQN()\n",
    "\n",
    "print(\"%s\\tStarting training for 300 episodes...\" % (datetime.now().time()))\n",
    "for e in range(300):\n",
    "    dqn.run_episode(e)\n",
    "print(\"%s\\t\\t...done!\" % (datetime.now().time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, layer_size=256):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, layer_size)\n",
    "        self.l2 = nn.Linear(layer_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.softmax(self.l2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartpolePolicyGradient():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        self.model = PolicyNetwork()\n",
    "        self.memory = ReplayMemory(10000)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), 0.001)\n",
    "        self.steps_done = 0\n",
    "        self.episode_durations = []\n",
    "        \n",
    "        self.gamma = 0.8\n",
    "        \n",
    "    def discount_rewards(self, r):\n",
    "        '''выдаём дисконтированные награды'''\n",
    "        discounted_r = torch.zeros(r.size())\n",
    "        running_add = 0\n",
    "        for t in reversed(range(len(r))):\n",
    "            running_add = running_add * self.gamma + r[t]\n",
    "            discounted_r[t] = running_add\n",
    "\n",
    "        return discounted_r\n",
    "\n",
    "    def run_episode(self, e=0):\n",
    "        state = self.env.reset()\n",
    "        reward_sum = 0\n",
    "        xs = torch.tensor([], dtype=torch.float32)\n",
    "        ys = torch.tensor([], dtype=torch.float32)\n",
    "        rewards = torch.tensor([], dtype=torch.float32)\n",
    "        num_step = 0\n",
    "\n",
    "        while True:\n",
    "            x = torch.tensor([state], dtype=torch.float32)\n",
    "            xs = torch.cat([xs, x])\n",
    "\n",
    "            # считаем вероятности действий и выбираем одно из двух\n",
    "            action_prob = self.model(Variable(x))\n",
    "            action = 0 if random.random() < action_prob.data[0][0] else 1\n",
    "\n",
    "            y = torch.tensor([[1, 0]] if action == 0 else [[0, 1]], dtype=torch.float32)\n",
    "            ys = torch.cat([ys, y])\n",
    "\n",
    "            state, reward, done, _ = self.env.step(action)\n",
    "            rewards = torch.cat([rewards, torch.tensor([[reward]], dtype=torch.float32)])\n",
    "            reward_sum += reward\n",
    "            num_step += 1\n",
    "\n",
    "            if done or num_step >= 500:\n",
    "                # считаем дисконтированные награды\n",
    "                targets = self.discount_rewards(rewards)\n",
    "                \n",
    "                # нормализуем награды (это baseline)\n",
    "                targets = (targets - targets.mean())/(targets.std() + 1e-6)\n",
    "                \n",
    "                loss = self.learn(xs, ys, targets)\n",
    "                print(\"\\tepisode %d finished after %d steps\" % (e, num_step))\n",
    "                self.episode_durations.append(num_step)\n",
    "                break\n",
    "\n",
    "    def learn(self, x, y, targets):\n",
    "        # предсказания вероятностей действий\n",
    "        action_pred = self.model(Variable(x))\n",
    "        y = Variable(y, requires_grad=True)\n",
    "        targets = Variable(targets)\n",
    "        log_lik = -y * torch.log(action_pred)\n",
    "        log_lik_adv = log_lik * targets\n",
    "        loss = torch.sum(log_lik_adv, 1).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:40.750596\tStarting training for 300 episodes...\n",
      "\tepisode 0 finished after 35 steps\n",
      "\tepisode 1 finished after 19 steps\n",
      "\tepisode 2 finished after 25 steps\n",
      "\tepisode 3 finished after 21 steps\n",
      "\tepisode 4 finished after 11 steps\n",
      "\tepisode 5 finished after 19 steps\n",
      "\tepisode 6 finished after 18 steps\n",
      "\tepisode 7 finished after 18 steps\n",
      "\tepisode 8 finished after 12 steps\n",
      "\tepisode 9 finished after 12 steps\n",
      "\tepisode 10 finished after 44 steps\n",
      "\tepisode 11 finished after 10 steps\n",
      "\tepisode 12 finished after 43 steps\n",
      "\tepisode 13 finished after 48 steps\n",
      "\tepisode 14 finished after 18 steps\n",
      "\tepisode 15 finished after 21 steps\n",
      "\tepisode 16 finished after 32 steps\n",
      "\tepisode 17 finished after 17 steps\n",
      "\tepisode 18 finished after 18 steps\n",
      "\tepisode 19 finished after 13 steps\n",
      "\tepisode 20 finished after 46 steps\n",
      "\tepisode 21 finished after 22 steps\n",
      "\tepisode 22 finished after 13 steps\n",
      "\tepisode 23 finished after 15 steps\n",
      "\tepisode 24 finished after 26 steps\n",
      "\tepisode 25 finished after 15 steps\n",
      "\tepisode 26 finished after 17 steps\n",
      "\tepisode 27 finished after 14 steps\n",
      "\tepisode 28 finished after 17 steps\n",
      "\tepisode 29 finished after 17 steps\n",
      "\tepisode 30 finished after 18 steps\n",
      "\tepisode 31 finished after 16 steps\n",
      "\tepisode 32 finished after 18 steps\n",
      "\tepisode 33 finished after 11 steps\n",
      "\tepisode 34 finished after 57 steps\n",
      "\tepisode 35 finished after 13 steps\n",
      "\tepisode 36 finished after 16 steps\n",
      "\tepisode 37 finished after 26 steps\n",
      "\tepisode 38 finished after 33 steps\n",
      "\tepisode 39 finished after 25 steps\n",
      "\tepisode 40 finished after 22 steps\n",
      "\tepisode 41 finished after 20 steps\n",
      "\tepisode 42 finished after 34 steps\n",
      "\tepisode 43 finished after 32 steps\n",
      "\tepisode 44 finished after 39 steps\n",
      "\tepisode 45 finished after 72 steps\n",
      "\tepisode 46 finished after 46 steps\n",
      "\tepisode 47 finished after 16 steps\n",
      "\tepisode 48 finished after 62 steps\n",
      "\tepisode 49 finished after 18 steps\n",
      "\tepisode 50 finished after 11 steps\n",
      "\tepisode 51 finished after 12 steps\n",
      "\tepisode 52 finished after 12 steps\n",
      "\tepisode 53 finished after 25 steps\n",
      "\tepisode 54 finished after 9 steps\n",
      "\tepisode 55 finished after 32 steps\n",
      "\tepisode 56 finished after 49 steps\n",
      "\tepisode 57 finished after 38 steps\n",
      "\tepisode 58 finished after 19 steps\n",
      "\tepisode 59 finished after 79 steps\n",
      "\tepisode 60 finished after 13 steps\n",
      "\tepisode 61 finished after 33 steps\n",
      "\tepisode 62 finished after 42 steps\n",
      "\tepisode 63 finished after 28 steps\n",
      "\tepisode 64 finished after 16 steps\n",
      "\tepisode 65 finished after 29 steps\n",
      "\tepisode 66 finished after 33 steps\n",
      "\tepisode 67 finished after 21 steps\n",
      "\tepisode 68 finished after 28 steps\n",
      "\tepisode 69 finished after 58 steps\n",
      "\tepisode 70 finished after 27 steps\n",
      "\tepisode 71 finished after 24 steps\n",
      "\tepisode 72 finished after 33 steps\n",
      "\tepisode 73 finished after 39 steps\n",
      "\tepisode 74 finished after 115 steps\n",
      "\tepisode 75 finished after 31 steps\n",
      "\tepisode 76 finished after 48 steps\n",
      "\tepisode 77 finished after 108 steps\n",
      "\tepisode 78 finished after 86 steps\n",
      "\tepisode 79 finished after 35 steps\n",
      "\tepisode 80 finished after 32 steps\n",
      "\tepisode 81 finished after 16 steps\n",
      "\tepisode 82 finished after 17 steps\n",
      "\tepisode 83 finished after 32 steps\n",
      "\tepisode 84 finished after 60 steps\n",
      "\tepisode 85 finished after 31 steps\n",
      "\tepisode 86 finished after 38 steps\n",
      "\tepisode 87 finished after 126 steps\n",
      "\tepisode 88 finished after 107 steps\n",
      "\tepisode 89 finished after 30 steps\n",
      "\tepisode 90 finished after 24 steps\n",
      "\tepisode 91 finished after 50 steps\n",
      "\tepisode 92 finished after 44 steps\n",
      "\tepisode 93 finished after 33 steps\n",
      "\tepisode 94 finished after 46 steps\n",
      "\tepisode 95 finished after 47 steps\n",
      "\tepisode 96 finished after 69 steps\n",
      "\tepisode 97 finished after 80 steps\n",
      "\tepisode 98 finished after 52 steps\n",
      "\tepisode 99 finished after 44 steps\n",
      "\tepisode 100 finished after 53 steps\n",
      "\tepisode 101 finished after 35 steps\n",
      "\tepisode 102 finished after 42 steps\n",
      "\tepisode 103 finished after 20 steps\n",
      "\tepisode 104 finished after 27 steps\n",
      "\tepisode 105 finished after 31 steps\n",
      "\tepisode 106 finished after 45 steps\n",
      "\tepisode 107 finished after 22 steps\n",
      "\tepisode 108 finished after 78 steps\n",
      "\tepisode 109 finished after 33 steps\n",
      "\tepisode 110 finished after 43 steps\n",
      "\tepisode 111 finished after 38 steps\n",
      "\tepisode 112 finished after 154 steps\n",
      "\tepisode 113 finished after 172 steps\n",
      "\tepisode 114 finished after 25 steps\n",
      "\tepisode 115 finished after 39 steps\n",
      "\tepisode 116 finished after 23 steps\n",
      "\tepisode 117 finished after 51 steps\n",
      "\tepisode 118 finished after 120 steps\n",
      "\tepisode 119 finished after 17 steps\n",
      "\tepisode 120 finished after 34 steps\n",
      "\tepisode 121 finished after 95 steps\n",
      "\tepisode 122 finished after 140 steps\n",
      "\tepisode 123 finished after 64 steps\n",
      "\tepisode 124 finished after 59 steps\n",
      "\tepisode 125 finished after 42 steps\n",
      "\tepisode 126 finished after 47 steps\n",
      "\tepisode 127 finished after 32 steps\n",
      "\tepisode 128 finished after 54 steps\n",
      "\tepisode 129 finished after 21 steps\n",
      "\tepisode 130 finished after 118 steps\n",
      "\tepisode 131 finished after 200 steps\n",
      "\tepisode 132 finished after 17 steps\n",
      "\tepisode 133 finished after 61 steps\n",
      "\tepisode 134 finished after 44 steps\n",
      "\tepisode 135 finished after 52 steps\n",
      "\tepisode 136 finished after 28 steps\n",
      "\tepisode 137 finished after 18 steps\n",
      "\tepisode 138 finished after 58 steps\n",
      "\tepisode 139 finished after 45 steps\n",
      "\tepisode 140 finished after 111 steps\n",
      "\tepisode 141 finished after 114 steps\n",
      "\tepisode 142 finished after 97 steps\n",
      "\tepisode 143 finished after 46 steps\n",
      "\tepisode 144 finished after 200 steps\n",
      "\tepisode 145 finished after 141 steps\n",
      "\tepisode 146 finished after 64 steps\n",
      "\tepisode 147 finished after 63 steps\n",
      "\tepisode 148 finished after 166 steps\n",
      "\tepisode 149 finished after 86 steps\n",
      "\tepisode 150 finished after 27 steps\n",
      "\tepisode 151 finished after 115 steps\n",
      "\tepisode 152 finished after 75 steps\n",
      "\tepisode 153 finished after 149 steps\n",
      "\tepisode 154 finished after 71 steps\n",
      "\tepisode 155 finished after 156 steps\n",
      "\tepisode 156 finished after 101 steps\n",
      "\tepisode 157 finished after 34 steps\n",
      "\tepisode 158 finished after 118 steps\n",
      "\tepisode 159 finished after 192 steps\n",
      "\tepisode 160 finished after 39 steps\n",
      "\tepisode 161 finished after 69 steps\n",
      "\tepisode 162 finished after 159 steps\n",
      "\tepisode 163 finished after 198 steps\n",
      "\tepisode 164 finished after 123 steps\n",
      "\tepisode 165 finished after 200 steps\n",
      "\tepisode 166 finished after 174 steps\n",
      "\tepisode 167 finished after 186 steps\n",
      "\tepisode 168 finished after 145 steps\n",
      "\tepisode 169 finished after 56 steps\n",
      "\tepisode 170 finished after 143 steps\n",
      "\tepisode 171 finished after 200 steps\n",
      "\tepisode 172 finished after 53 steps\n",
      "\tepisode 173 finished after 200 steps\n",
      "\tepisode 174 finished after 191 steps\n",
      "\tepisode 175 finished after 97 steps\n",
      "\tepisode 176 finished after 109 steps\n",
      "\tepisode 177 finished after 167 steps\n",
      "\tepisode 178 finished after 111 steps\n",
      "\tepisode 179 finished after 21 steps\n",
      "\tepisode 180 finished after 96 steps\n",
      "\tepisode 181 finished after 44 steps\n",
      "\tepisode 182 finished after 12 steps\n",
      "\tepisode 183 finished after 107 steps\n",
      "\tepisode 184 finished after 114 steps\n",
      "\tepisode 185 finished after 35 steps\n",
      "\tepisode 186 finished after 200 steps\n",
      "\tepisode 187 finished after 166 steps\n",
      "\tepisode 188 finished after 115 steps\n",
      "\tepisode 189 finished after 147 steps\n",
      "\tepisode 190 finished after 200 steps\n",
      "\tepisode 191 finished after 141 steps\n",
      "\tepisode 192 finished after 195 steps\n",
      "\tepisode 193 finished after 142 steps\n",
      "\tepisode 194 finished after 78 steps\n",
      "\tepisode 195 finished after 200 steps\n",
      "\tepisode 196 finished after 175 steps\n",
      "\tepisode 197 finished after 88 steps\n",
      "\tepisode 198 finished after 149 steps\n",
      "\tepisode 199 finished after 200 steps\n",
      "\tepisode 200 finished after 160 steps\n",
      "\tepisode 201 finished after 128 steps\n",
      "\tepisode 202 finished after 125 steps\n",
      "\tepisode 203 finished after 141 steps\n",
      "\tepisode 204 finished after 126 steps\n",
      "\tepisode 205 finished after 200 steps\n",
      "\tepisode 206 finished after 84 steps\n",
      "\tepisode 207 finished after 200 steps\n",
      "\tepisode 208 finished after 114 steps\n",
      "\tepisode 209 finished after 200 steps\n",
      "\tepisode 210 finished after 131 steps\n",
      "\tepisode 211 finished after 172 steps\n",
      "\tepisode 212 finished after 116 steps\n",
      "\tepisode 213 finished after 58 steps\n",
      "\tepisode 214 finished after 94 steps\n",
      "\tepisode 215 finished after 155 steps\n",
      "\tepisode 216 finished after 135 steps\n",
      "\tepisode 217 finished after 167 steps\n",
      "\tepisode 218 finished after 124 steps\n",
      "\tepisode 219 finished after 168 steps\n",
      "\tepisode 220 finished after 147 steps\n",
      "\tepisode 221 finished after 158 steps\n",
      "\tepisode 222 finished after 153 steps\n",
      "\tepisode 223 finished after 133 steps\n",
      "\tepisode 224 finished after 107 steps\n",
      "\tepisode 225 finished after 130 steps\n",
      "\tepisode 226 finished after 144 steps\n",
      "\tepisode 227 finished after 131 steps\n",
      "\tepisode 228 finished after 27 steps\n",
      "\tepisode 229 finished after 127 steps\n",
      "\tepisode 230 finished after 94 steps\n",
      "\tepisode 231 finished after 200 steps\n",
      "\tepisode 232 finished after 78 steps\n",
      "\tepisode 233 finished after 137 steps\n",
      "\tepisode 234 finished after 156 steps\n",
      "\tepisode 235 finished after 193 steps\n",
      "\tepisode 236 finished after 53 steps\n",
      "\tepisode 237 finished after 152 steps\n",
      "\tepisode 238 finished after 200 steps\n",
      "\tepisode 239 finished after 200 steps\n",
      "\tepisode 240 finished after 130 steps\n",
      "\tepisode 241 finished after 123 steps\n",
      "\tepisode 242 finished after 200 steps\n",
      "\tepisode 243 finished after 108 steps\n",
      "\tepisode 244 finished after 200 steps\n",
      "\tepisode 245 finished after 157 steps\n",
      "\tepisode 246 finished after 143 steps\n",
      "\tepisode 247 finished after 131 steps\n",
      "\tepisode 248 finished after 168 steps\n",
      "\tepisode 249 finished after 200 steps\n",
      "\tepisode 250 finished after 143 steps\n",
      "\tepisode 251 finished after 200 steps\n",
      "\tepisode 252 finished after 200 steps\n",
      "\tepisode 253 finished after 200 steps\n",
      "\tepisode 254 finished after 141 steps\n",
      "\tepisode 255 finished after 200 steps\n",
      "\tepisode 256 finished after 22 steps\n",
      "\tepisode 257 finished after 195 steps\n",
      "\tepisode 258 finished after 200 steps\n",
      "\tepisode 259 finished after 200 steps\n",
      "\tepisode 260 finished after 151 steps\n",
      "\tepisode 261 finished after 155 steps\n",
      "\tepisode 262 finished after 98 steps\n",
      "\tepisode 263 finished after 200 steps\n",
      "\tepisode 264 finished after 200 steps\n",
      "\tepisode 265 finished after 183 steps\n",
      "\tepisode 266 finished after 112 steps\n",
      "\tepisode 267 finished after 173 steps\n",
      "\tepisode 268 finished after 71 steps\n",
      "\tepisode 269 finished after 140 steps\n",
      "\tepisode 270 finished after 200 steps\n",
      "\tepisode 271 finished after 200 steps\n",
      "\tepisode 272 finished after 156 steps\n",
      "\tepisode 273 finished after 200 steps\n",
      "\tepisode 274 finished after 143 steps\n",
      "\tepisode 275 finished after 200 steps\n",
      "\tepisode 276 finished after 172 steps\n",
      "\tepisode 277 finished after 200 steps\n",
      "\tepisode 278 finished after 71 steps\n",
      "\tepisode 279 finished after 45 steps\n",
      "\tepisode 280 finished after 200 steps\n",
      "\tepisode 281 finished after 39 steps\n",
      "\tepisode 282 finished after 200 steps\n",
      "\tepisode 283 finished after 180 steps\n",
      "\tepisode 284 finished after 200 steps\n",
      "\tepisode 285 finished after 163 steps\n",
      "\tepisode 286 finished after 141 steps\n",
      "\tepisode 287 finished after 139 steps\n",
      "\tepisode 288 finished after 200 steps\n",
      "\tepisode 289 finished after 200 steps\n",
      "\tepisode 290 finished after 200 steps\n",
      "\tepisode 291 finished after 175 steps\n",
      "\tepisode 292 finished after 74 steps\n",
      "\tepisode 293 finished after 200 steps\n",
      "\tepisode 294 finished after 158 steps\n",
      "\tepisode 295 finished after 108 steps\n",
      "\tepisode 296 finished after 135 steps\n",
      "\tepisode 297 finished after 198 steps\n",
      "\tepisode 298 finished after 196 steps\n",
      "\tepisode 299 finished after 200 steps\n",
      "19:16:51.006486\t\t...done!\n"
     ]
    }
   ],
   "source": [
    "pg = CartpolePolicyGradient()\n",
    "\n",
    "print(\"%s\\tStarting training for 300 episodes...\" % (datetime.now().time()))\n",
    "for e in range(300):\n",
    "    pg.run_episode(e)\n",
    "print(\"%s\\t\\t...done!\" % (datetime.now().time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализуем крестики-нолики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows, n_cols, n_win):\n",
    "        self.n_rows = n_rows\n",
    "        self.n_cols = n_cols\n",
    "        self.n_win = n_win\n",
    "\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.gameOver = False\n",
    "        self.boardHash = None\n",
    "        # ход первого игрока\n",
    "        self.curTurn = 1\n",
    "        self.emptySpaces = None\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "#             print((i,j))\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(env, pi, showtext=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Рисуем доску с оценками из стратегии pi'''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    X, Y = np.meshgrid(np.arange(0, env.n_rows), np.arange(0, env.n_rows))\n",
    "    Z = np.zeros((env.n_rows, env.n_cols)) + .01\n",
    "    s, actions = env.getHash(), env.getEmptySpaces()\n",
    "    if pi is not None and s in pi.Q:\n",
    "        for i, a in enumerate(actions):\n",
    "            Z[a[0], a[1]] = pi.Q[s][i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    surf = ax.imshow(Z, cmap=plt.get_cmap('Accent', 10), vmin=-1, vmax=1)\n",
    "    if showtext:\n",
    "        for i,a in enumerate(actions):\n",
    "            if pi is not None and s in pi.Q:\n",
    "                ax.text( a[1] , a[0] , \"%.3f\" % pi.Q[s][i], fontsize=fontq, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "#             else:\n",
    "#                 ax.text( a[1] , a[0] , \"???\", fontsize=fontq, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "    for i in range(env.n_rows):\n",
    "        for j in range(env.n_cols):\n",
    "            if env.board[i, j] == -1:\n",
    "                ax.text(j, i, \"O\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "            if env.board[i, j] == 1:\n",
    "                ax.text(j, i, \"X\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "    cbar = plt.colorbar(surf, ticks=[0, 1])\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def get_and_print_move(env, pi, s, actions, random=False, verbose=True, fontq=20, fontx=60):\n",
    "    '''Делаем ход, рисуем доску'''\n",
    "    plot_board(env, pi, fontq=fontq, fontx=fontx)\n",
    "    if verbose and (pi is not None):\n",
    "        if s in pi.Q:\n",
    "            for i,a in enumerate(actions):\n",
    "                print(i, a, pi.Q[s][i])\n",
    "        else:\n",
    "            print(\"Стратегия не знает, что делать...\")\n",
    "    if random:\n",
    "        return np.random.randint(len(actions))\n",
    "    else:\n",
    "        return pi.getActionGreedy(s, len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_game(env, pi1, pi2, random_crosses=False, random_naughts=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Играем тестовую партию между стратегиями или со случайными ходами, рисуем ход игры'''\n",
    "    done = False\n",
    "    env.reset()\n",
    "    while not done:\n",
    "        s, actions = env.getHash(), env.getEmptySpaces()\n",
    "        if env.curTurn == 1:\n",
    "            a = get_and_print_move(env, pi1, s, actions, random=random_crosses, verbose=verbose, fontq=fontq, fontx=fontx)\n",
    "        else:\n",
    "            a = get_and_print_move(env, pi2, s, actions, random=random_naughts, verbose=verbose, fontq=fontq, fontx=fontx)\n",
    "        observation, reward, done, info = env.step(actions[a])\n",
    "        if reward == 1:\n",
    "            print(\"Крестики выиграли!\")\n",
    "            plot_board(env, None, showtext=False, fontq=fontq, fontx=fontx)\n",
    "        if reward == -1:\n",
    "            print(\"Нолики выиграли!\")\n",
    "            plot_board(env, None, showtext=False, fontq=fontq, fontx=fontx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=15, n_cols=15, n_win=5)\n",
    "plot_test_game(env, None, None, random_crosses=True, random_naughts=True, verbose=True, fontx=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
